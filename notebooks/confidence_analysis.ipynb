{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API Confidence Analysis\n",
    "\n",
    "This notebook demonstrates how to analyze the confidence of an OpenAI API response using log probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import math\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Set your API key from environment variable (safer than hardcoding)\n",
    "# Make sure to set the OPENAI_API_KEY environment variable before running this cell.\n",
    "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query with a factual question\n",
    "query = \"What is the capital of Canada?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the API call with logprobs enabled\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3,\n",
    "    max_tokens=25,\n",
    "    temperature=0  # Use deterministic sampling for consistency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract answer and log probabilities\n",
    "answer = response.choices[0].message.content\n",
    "logprobs_data = response.choices[0].logprobs\n",
    "\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(\"\\nToken-by-token analysis:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average confidence\n",
    "total_logprob = 0\n",
    "token_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each token\n",
    "for token_info in logprobs_data.content:\n",
    "    token = token_info.token\n",
    "    token_logprob = token_info.logprob\n",
    "    token_prob = math.exp(token_logprob)  # Convert log probability to probability\n",
    "    \n",
    "    # Get alternative tokens\n",
    "    alternatives = {t.token: math.exp(t.logprob) for t in token_info.top_logprobs}\n",
    "    \n",
    "    # Only process non-whitespace tokens for better analysis\n",
    "    if token.strip():\n",
    "        total_logprob += token_logprob\n",
    "        token_count += 1\n",
    "        \n",
    "        print(f\"\\nToken: '{token}'\")\n",
    "        print(f\"Confidence: {token_prob:.4f} (logprob: {token_logprob:.4f})\")\n",
    "        \n",
    "        # Print top alternatives\n",
    "        print(\"Top alternatives:\")\n",
    "        for alt_token, alt_prob in sorted(alternatives.items(), key=lambda x: x[1], reverse=True):\n",
    "            if alt_token != token:  # Skip the selected token\n",
    "                print(f\"  '{alt_token}': {alt_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall confidence metrics\n",
    "if token_count > 0:\n",
    "    avg_logprob = total_logprob / token_count\n",
    "    avg_prob = math.exp(avg_logprob)\n",
    "    \n",
    "    print(\"\\nOverall confidence metrics:\")\n",
    "    print(f\"Average token logprob: {avg_logprob:.4f}\")\n",
    "    print(f\"Average token probability: {avg_prob:.4f}\")\n",
    "    \n",
    "    # Interpret confidence\n",
    "    if avg_prob > 0.9:\n",
    "        confidence_level = \"Very high confidence\"\n",
    "    elif avg_prob > 0.7:\n",
    "        confidence_level = \"High confidence\"\n",
    "    elif avg_prob > 0.5:\n",
    "        confidence_level = \"Moderate confidence\"\n",
    "    else:\n",
    "        confidence_level = \"Low confidence\"\n",
    "        \n",
    "    print(f\"Confidence assessment: {confidence_level}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}